
These codes are written by Dr. Obaidur Rahaman

Deep learning architecture. We used python and PyTorch programming languages to construct the deep learning framework. We combined the different features (GNN, MBTR and MD) for deep learning the targets.
GNNs were built using the message passing neural net-work4 (NNConv) as implemented in PyTorch. The number of convolution layers in GNN is hyperparameter of the model. However, we limited this to 3 in order to reduce the number of hyperparameters and thus complexity of the model. Gated Recurrent Unit (GRU)33 was used as the up-date function for GNN.
Similarly, both the number of neurons and number of hid-den layers processing MBTR and MD features, as well as the final features are hyper parameters of the model. In or-der to reduce the total number of hyperparameters, we fixed the number of hidden layers to 2. However, the number of neurons in the layer is kept as a hyperparameter. The number of neurons was gradually reduced in the more advanced layers, constructing a funnel like structure.
 
A batch size of 64 was used to balance between efficiency and accuracy. AdamW with amsgrad turned on was used as the optimizer. Applying a slight weight decay (=0.005) was useful in achieving regularization and preventing over-fitting. The learning rate was kept as a hyperparameter of the model. A scheduler was used to modify the learning rate during the training. The training of the model was per-formed using GPU. 
The OE62 dataset was randomly split into 70%, 15% and 15% for training, validation and test, respectively. The number of epochs required to achieve satisfactory accuracy was dependent on the type of the target.

INSTALLATION

Follow the instructions in the README file inside graphNN_tools folder

DEPENDENCIES
Install the following packages (the latest versions of the packages should work fine. However, the code is tested on the versions reported below):

Python 3.7.4
PyTorch 1.2.0
CUDA (python -c "import torch; print(torch.version.cuda)") 10.0.130
PyTorch geometric (from source)
Rdkit 2019.09.3
pandas 0.25.2
matplotlib 3.1.3
Scipy 1.4.1
numpy 1.18.1
pickle 4.0
sklearn 0.22.1
collections
PyAstronomy
ase

CREATE DATAFRAME

Create a dataframe containing the SMILES codes of the molecules with column name "smiles".
If available, provide the XYZ coordinates with column name "xyz".
Store the targets in seperate columns (more than one if available). List the column names of the targets in /train/data/target_terms_all.txt file. 
Store the dataframe as df.csv in /train/data folder.

PREPROCESS

Go to train/models folder

Execute the following command:

python3 1-preprocess_GNN.py

This will extract the features from smiles code (optionally also from xyz coordinates) to construct molecular graphs.

The MBTR features can be generated by running the command:

python3 2-preprocess_MBTR.py

The above step can be ignored if MBTR features are not wanted.

TRAIN

Open the 3-run.py file and modify the following:

end: put the number of datapoints in the dataset
num_epochs: Number of epochs to run
GNN, MD, MBTR: value 0 to turn off, value 1 to turn on
target_term: list all the targets in the dataset
hyper: value 0 to turn off, value 1 to turn on. It is recommended to turn the hyperparameter tuning on becasue 
the hyperparameters are dependant on the specific dataset and specific target. It is necessary to tune the 
hyperparameters for each combination of features (GNN + MD or MD + MBTR etc)

Make sure you have GPU available and run the following command:

python3 3-run.py

The final results are stored in the results/all_results.txt file. The tuned hyperparameters are stored in the 
results/all_hyperparameters.txt file. 

How to check for overfitting and plotting the results:

Open the 3-run.py file in an editor that allows running part of the code, for example Jupyter, spyder or VS code. Run all the lines
before READ DATASET section (set show_plots = 1). Then run the two lines:

for target_term in ['homo']: #['homo', 'lumo']:
    print(target_term)

Then run these two lines:

trainData = pd.read_csv("../results/%s/train_CNN=%s_MD=%s_MBTR=%s.csv" % (target_term, GNN, MD, MBTR))
testData = pd.read_csv("../results/%s/test_CNN=%s_MD=%s_MBTR=%s.csv" % (target_term, GNN, MD, MBTR))   

To check overfitting, run the following line:

gnn.plot_losses(target_term, GNN, MD, MBTR)

To plot the results run the following line:

gnn.plot_results(trainData, testData, target_term, show = show_plots)

Please contact ramieor@gmail.com if you have any questions.

